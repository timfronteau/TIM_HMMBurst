{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final: saving all HMM data, of which the states timecourses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The libraries and methods we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/5f/47e578b3ae79e2624e205445ab77a1848acdaa2929a00eeef6b16eaaeb20/numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 60kB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.16.6\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bfaf7bc4dea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_oneIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from loader import load_oneIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from hmmlearn import hmm\n",
    "import scipy.signal as signal\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"E:/timot/Documents/1 - Centrale Marseille/0.5 - Semestre S8/Stage/NIC_250819\"\n",
    "file = \"FCK_LOCKED_IC_JYOTIKA_250819.mat\"\n",
    "\n",
    "path = f\"{directory}/{file}\"\n",
    "\n",
    "mat_file = h5py.File(path, \"r\")\n",
    "cells_refs = mat_file['FCK_LOCKED_IC_JYOTIKA']\n",
    "\n",
    "n_IC = 4\n",
    "n_subj = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumputing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedx function copies the `x` array len(lags) times into `xe`\n",
    "# with lags (i.e. time delays) between lags[0] and lags[-1] (we implement the time-delay array for the HMM).\n",
    "\n",
    "def embedx(x, lags):\n",
    "    \n",
    "    Xe = np.zeros((x.shape[1], x.shape[0],  len(lags)))\n",
    "\n",
    "    for l in range(len(lags)):\n",
    "        Xe[:, :, l] = np.roll(x, lags[l], axis=0).swapaxes(0, 1)\n",
    "\n",
    "    # Remove edges\n",
    "    valid = np.ones((x.shape[0], 1), dtype=np.int8)\n",
    "    valid[:np.abs(np.min(lags)), :] = 0\n",
    "    valid[-np.abs(np.max(lags)):, :] = 0\n",
    "\n",
    "    Xe = Xe[:, valid[:, 0] == 1, :]\n",
    "\n",
    "    return Xe, valid\n",
    "\n",
    "\n",
    "# The hmm_tde function finds parameters for the HMM,\n",
    "# then uses them to determine the probability of presence of each found state over time.\n",
    "\n",
    "def hmm_tde(y: np.array, lags, subj, IC, n_lags, n_states=3, n_iter=100, n_components=8, \n",
    "            covariance_type='full', model_type='GMMHMM', tol=0.01, n_mix=1, **kwargs):\n",
    "    \n",
    "    if model_type=='GMMHMM':\n",
    "        model = hmm.GMMHMM(n_components=n_states, n_iter=n_iter,\n",
    "                            covariance_type=covariance_type, tol=tol, n_mix=n_mix, **kwargs)\n",
    "        \n",
    "    elif model_type=='GaussianHMM':\n",
    "        model = hmm.GaussianHMM(n_components=n_states, n_iter=n_iter,\n",
    "                            covariance_type=covariance_type, tol=tol, **kwargs)\n",
    "        \n",
    "    elif model_type=='MultinomialHMM':\n",
    "        model = hmm.MultinomialHMM(n_components=n_states, n_iter=n_iter, tol=tol, **kwargs)\n",
    "    \n",
    "    else: \n",
    "        return \"Non-exixting model_type. Please choose 'GMMHMM' or 'GaussianHMM' or 'MultinomialHMM'. default='GMMHMM'\"\n",
    "        \n",
    "    model.fit(y)\n",
    "    gamma = model.predict_proba(y)\n",
    "\n",
    "    return gamma, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The routine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and parameters:\n",
    "|_ 58delays x (7s x 256Hz x 10trials)   -----PCA-----> |_ 40components x (7s x 256Hz x 10trials) -----> |_ TDE-HMM\n",
    "                                                                                                        (\n",
    "                                                                                                        1 Gaussian/state,\n",
    "                                                                                                        3 states\n",
    "                                                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters we change to hope for some results\n",
    "lags = np.arange(-29, 29)\n",
    "n_lags = lags.shape[0]\n",
    "n_iter=100\n",
    "n_states=3    # for the Hidden Markov Model\n",
    "n_components=40     # For the principal component analysis\n",
    "covariance_type='diag'\n",
    "model_type='GMMHMM'\n",
    "tol=0.01\n",
    "n_mix=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = [i for i in range(2,9)] + [i for i in range(10,13)] + [14] + [i for i in range(16, n_subj+1)] \n",
    "                                                                            # All except subjects 1, 9, 13, 15\n",
    "complete_time = tm.time()\n",
    "for subj in subj_list:\n",
    "    print(f\"---- SUBJECT{subj} ----\")\n",
    "    start_time = tm.time()\n",
    "    datall = []\n",
    "    IC_list = []\n",
    "    for IC in range(1, n_IC+1):\n",
    "        try:\n",
    "            data, n_trials = load_oneIC(mat_file, cells_refs, subj, IC, comp=False)\n",
    "            big_timecourse = np.concatenate([data[f'raw_timecourse_256Hz'][i] for i in range(n_trials)])\n",
    "            x = big_timecourse.reshape(-1, 1)\n",
    "            xe, valid = embedx(x, lags)\n",
    "            pca = PCA(n_components=n_components)\n",
    "            y = pca.fit_transform(xe[0, :, :])\n",
    "            datall.append(y)\n",
    "            IC_list.append(IC)\n",
    "            print(f\"IC{IC} loaded\")\n",
    "        except:\n",
    "            pass\n",
    "    y = np.concatenate(datall, axis=1)\n",
    "    gamma, model = hmm_tde(y, lags, subj, IC, n_lags, n_iter=n_iter, n_states=n_states, n_components=n_components, \n",
    "                           covariance_type=covariance_type, model_type=model_type, tol=tol, n_mix=n_mix)\n",
    "    print(\"Saving the model\")\n",
    "    with open(f\"tde-hmm2/pkl_files/su{subj}All_lg{n_lags}co{n_components}st{n_states}\"\n",
    "        +f\"{n_mix}\"+model_type+\"_model.pkl\", \"wb\") as file: pickle.dump(model, file)\n",
    "    print(\"Saving the states timecourse\")\n",
    "    for IC in IC_list:\n",
    "        \n",
    "    print(\"%s seconds\" % (tm.time() - start_time))\n",
    "    start_time = tm.time()\n",
    "\n",
    "    # Saving the Power Spectral Density of each state\n",
    "    print(\"Computing the PSD of each states and saving a plot\")\n",
    "    psd_all, freqs, max_power = show_bigstates(\n",
    "        gamma, n_states, xe, # the data we need for the plot\n",
    "        subj, IC, # which IC of which subject is of interest here\n",
    "        n_components, n_lags, covariance_type, model_type, n_mix, # infos we put in the .png name if we want to save it\n",
    "    )\n",
    "    print(\"Saving the PSD of each state\")\n",
    "    psdxr = xr.DataArray(\n",
    "        psd_all,\n",
    "        dims=['states', 'power'],\n",
    "        coords={\n",
    "            \"subject\": subj,\n",
    "            \"IC\": IC,\n",
    "        },\n",
    "    )\n",
    "    # !!! ICI ajouter le freqs array dedans !!!\n",
    "    ds = xr.Dataset({\"states_psd\": psdxr},)\n",
    "    ds.to_netcdf(f\"tde-hmm2/nc_files/su{subj}IC{IC}-states_psd.nc\")\n",
    "\n",
    "    # Saving a plot of probability timecourses of the states over the tfr \n",
    "    print(\"Saving a plot of the states timecourses over a plot of the tfr\")\n",
    "    time = data['time_axis']\n",
    "    bigtime = np.concatenate([time+4+(7*i) for i in range(3)])\n",
    "    bigtfr = np.concatenate([data[f'tfr_256Hz trial{i+1}'] for i in range(3)], axis=2)\n",
    "    plot_hmm_over_bigtfr(   \n",
    "        bigtime, bigtfr, gamma, lags, n_states, max_power, # the data we need for the plot\n",
    "        subj, IC, # which IC of which subject is of interest here, how many trials\n",
    "        n_components, n_lags, covariance_type, model_type, n_mix, # infos we put in the .png name if we want to save it\n",
    "    )\n",
    "    print(\"%s seconds\" % (tm.time() - start_time))\n",
    "    print(f\"subj{subj}, IC{IC}: OK\")\n",
    "\n",
    "sec_time = tm.time() - complete_time\n",
    "hr_time = int(sec_time/3600)\n",
    "sec_time = sec_time - (hr_time*3600)\n",
    "mn_time = int(sec_time/60)\n",
    "sec_time = sec_time - (mn_time*60)\n",
    "print(f\"{hr_time}h{mn_time}mn{sec_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    {\n",
    "        \"states_timecourse\": ((\"IC\",\"trials\",\"time\", \"states\"), np.concatenate((gamma[]))),\n",
    "        \"states_psd\": ((\"IC\", \"states\", \"freq\"), np.concatenate((psds))),\n",
    "    },\n",
    "    {\n",
    "        \"IC\":IC_list,\n",
    "        \"time\":data[\"time_axis\"],\n",
    "        \"states\":np.arange(n_states),\n",
    "        \"freq\": freqs,\n",
    "    }\n",
    ")\n",
    "ds.to_netcdf(f\"tde-hmm2/nc_files/su{subj}-{n_states}states_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the raw timecourse\n",
      "Loading the raw timecourse\n",
      "Loading the raw timecourse\n",
      "Loading the raw timecourse\n"
     ]
    }
   ],
   "source": [
    "subj = 2\n",
    "\n",
    "# Loading all data for subject{subj}, IC{IC}\n",
    "datall = []\n",
    "for IC in range(1, n_IC+1):\n",
    "    data, n_trials = load_oneIC(mat_file, cells_refs, subj, IC, comp=False)\n",
    "    big_timecourse = np.concatenate([data[f'raw_timecourse_256Hz'][i] for i in range(n_trials)])\n",
    "    x = big_timecourse.reshape(-1, 1)\n",
    "    xe, valid = embedx(x, lags)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    y = pca.fit_transform(xe[0, :, :])\n",
    "    datall.append(y)\n",
    "y = np.concatenate(datall, axis=1)\n",
    "gamma, model = hmm_tde(y, lags, subj, IC, n_lags, n_iter=n_iter, n_states=n_states, n_components=n_components, \n",
    "                           covariance_type=covariance_type, model_type=model_type, tol=tol, n_mix=n_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1210218, 160)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.concatenate(datall, axis=1)\n",
    "gamma, model = hmm_tde(y, lags, subj, IC, n_lags, n_iter=n_iter, n_states=n_states, n_components=n_components, \n",
    "                           covariance_type=covariance_type, model_type=model_type, tol=tol, n_mix=n_mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the raw timecourse\n",
      "Loading the raw timecourse\n",
      "Loading the raw timecourse\n",
      "Loading the raw timecourse\n"
     ]
    }
   ],
   "source": [
    "subj = 2\n",
    "\n",
    "# Loading all data for subject{subj}, IC{IC}\n",
    "datall = []\n",
    "for IC in range(1, n_IC+1):\n",
    "    data, n_trials = load_oneIC(mat_file, cells_refs, subj, IC, comp=False)\n",
    "    big_timecourse = np.concatenate([data[f'raw_timecourse_256Hz'][i] for i in range(n_trials)])\n",
    "    x = big_timecourse.reshape(-1, 1)\n",
    "    xe, valid = embedx(x, lags)\n",
    "    datall.append(xe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1210218, 232)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xe = np.concatenate(datall, axis=2)\n",
    "xe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "y = pca.fit_transform(xe[0, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1210218, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, model = hmm_tde(y, lags, subj, IC, n_lags, n_iter=n_iter, n_states=n_states, n_components=n_components, \n",
    "                           covariance_type=covariance_type, model_type=model_type, tol=tol, n_mix=n_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bigstates(\n",
    "    gamma, n_states, xe, # the data we need for the plot\n",
    "    \n",
    "    subj, IC, # which IC of which subject is of interest here\n",
    "    \n",
    "    n_components, n_lags, covariance_type, model_type, n_mix, # infos we put in the .png name if we want to save it\n",
    "):\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.title('Power Spectrum Density')\n",
    "    max_power = np.zeros(n_states)\n",
    "    psd_all = np.zeros((n_states, 196))\n",
    "    for i in range(n_states):\n",
    "\n",
    "        # Compute PSD separately for each lag\n",
    "        tot = []\n",
    "        for seg in xe[0, gamma[:, i]> .6, :].T:\n",
    "            freqs, psd = signal.welch(x=seg, fs=256, nfft=1000)\n",
    "            tot.append(psd)\n",
    "        psd = np.mean(np.asarray(tot), 0)\n",
    "        \n",
    "        max_power[i] = np.amax(psd[80:])\n",
    "        \n",
    "        psd_all[i] = psd[:196]\n",
    "        plt.plot(freqs[:196], psd_all[i])\n",
    "    \n",
    "    plt.ylabel('PSD')\n",
    "    plt.xlabel('Frequencies (Hz)')\n",
    "    plt.legend([f'state {i+1}' for i in range(n_states)], loc='upper right')\n",
    "    plt.tight_layout()   \n",
    "\n",
    "    plt.savefig(f'tde-hmm2/png_files/test{ts}su{subj}IC{IC}All_lg{n_lags}co{n_components}st{n_states}'\n",
    "                    +f'{n_mix}'+model_type+'_states-info.png', dpi=600)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return psd_all, freqs[:196], max_power"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
