{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from loader import load_oneIC\n",
    "import h5py\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from hmmlearn import hmm\n",
    "import scipy.signal as signal\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wavelet_transform import wavelet_transform2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/INT/malfait.n/Documents/NIC_250819\"\n",
    "file = \"FCK_LOCKED_IC_JYOTIKA_250819.mat\"\n",
    "\n",
    "path = f\"{directory}/{file}\"\n",
    "\n",
    "mat_file = h5py.File(path, \"r\")\n",
    "cells_refs = mat_file['FCK_LOCKED_IC_JYOTIKA']\n",
    "\n",
    "n_IC = 4\n",
    "n_subj = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = \"tde-hmm2/Univariate/figures/\"\n",
    "data_dir = \"tde-hmm2/Univariate/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedx function copies the `x` array len(lags) times into `xe`\n",
    "# with lags (i.e. time delays) between lags[0] and lags[-1] (we implement the time-delay array for the HMM).\n",
    "\n",
    "def embedx(x, lags):\n",
    "    \n",
    "    Xe = np.zeros((x.shape[1], x.shape[0],  len(lags)))\n",
    "\n",
    "    for l in range(len(lags)):\n",
    "        Xe[:, :, l] = np.roll(x, lags[l], axis=0).swapaxes(0, 1)\n",
    "\n",
    "    # Remove edges\n",
    "    valid = np.ones((x.shape[0], 1), dtype=np.int8)\n",
    "    valid[:np.abs(np.min(lags)), :] = 0\n",
    "    valid[-np.abs(np.max(lags)):, :] = 0\n",
    "\n",
    "    Xe = Xe[:, valid[:, 0] == 1, :]\n",
    "\n",
    "    return Xe, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statesPSD(gamma, n_states, xe, fs=256/3):\n",
    "\n",
    "    psd_all = []\n",
    "    for i in range(n_states):\n",
    "\n",
    "        # Compute PSD separately for each lag\n",
    "        tot = []\n",
    "        for seg in xe[gamma[:, i]>(2/3), :].T:\n",
    "            freqs, psd = signal.welch(x=seg, fs=fs, nfft=1000)\n",
    "            tot.append(psd)\n",
    "        psd = np.mean(np.asarray(tot), 0)\n",
    "        psd_all.append(psd)\n",
    "    \n",
    "    psd_all = np.asarray(psd_all)\n",
    "    \n",
    "    return freqs, psd_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imput data parameters\n",
    "# subj_list = [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23] # All except 1, 9, 13, 15\n",
    "subj_list = [2, 3, 4, 6, 7, 8, 10, 11, 14, 16, 18, 19, 22] # same && all IC exist\n",
    "# subj_list = [2, 3]\n",
    "IC_list = [1, 2, 3, 4]\n",
    "downsamp_rate = 3\n",
    "# downsamp_rate = 1\n",
    "lags = np.arange(-5, 5)\n",
    "# lags = np.arange(-29, 29)\n",
    "# lags = np.arange(-11, 12)\n",
    "n_lags = lags.shape[0]\n",
    "apply_PCA = False  # Do we apply a PCA before inferring the HMM?\n",
    "n_components = 0     # Number of principal components in case of PCA\n",
    "# n_components = 40\n",
    "\n",
    "### HMM parameters\n",
    "model_type = 'GaussianHMM'\n",
    "covariance_type = 'full'\n",
    "# covariance_type = 'diag'  # ONLY IN CASE OF PCA\n",
    "n_iter = 100\n",
    "tol = 0.01\n",
    "\n",
    "### Output data parameters\n",
    "n_states_list = [3, 6]    # Number of hidden Markov states. Must be a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_time = tm.time()\n",
    "for n_states in n_states_list:\n",
    "    for subj in subj_list:\n",
    "        tcourses = []\n",
    "        psds = []\n",
    "        IC_new_list = []\n",
    "        for IC in IC_list: \n",
    "            start_time = tm.time()\n",
    "            try:\n",
    "                print(f\"---- SUBJECT{subj}, IC{IC} ----\")\n",
    "                # Loading all data for subject{subj}, IC{IC}\n",
    "                data, n_trials = load_oneIC(mat_file, cells_refs, subj, IC)\n",
    "                t_len = data[\"time_axis\"][::downsamp_rate].shape[0]            \n",
    "                # Finding and saving the model\n",
    "                big_timecourse = np.concatenate([data[f'raw_timecourse_256Hz'][i][::downsamp_rate] for i in range(n_trials)])\n",
    "                x = big_timecourse.reshape(-1, 1)\n",
    "                print(\"Computing and saving the model\")\n",
    "                xe, valid = embedx(data, lags)\n",
    "                if apply_PCA:\n",
    "                    pca = PCA(n_components=n_components)\n",
    "                    y = pca.fit_transform(xe[0, :, :])\n",
    "                else:\n",
    "                    y = xe[0, :, :]\n",
    "                model = hmm.GaussianHMM(n_components=n_states, n_iter=n_iter,\n",
    "                                covariance_type=covariance_type, tol=tol)\n",
    "                model.fit(y)\n",
    "                with open(data_dir + f\"su{subj}IC{IC}_lg{n_lags}co{n_components}st{n_states}\"\n",
    "                    +\"Univariate\"+model_type+\".pkl\", \"wb\") as file: pickle.dump(model, file)\n",
    "\n",
    "                # Computing and saving the states' Probability time courses and PSDs\n",
    "                print(\"Computing the probability time course and the PSD of each states\")\n",
    "                gamma = model.predict_proba(y)\n",
    "                tcourse = np.concatenate(\n",
    "                    (np.zeros((abs(lags[0]),n_states)), gamma, np.zeros((lags[-1],n_states)))\n",
    "                )\n",
    "                tcourse_trials = np.zeros((n_trials, t_len, n_states))\n",
    "                for tr in range(n_trials):\n",
    "                    tcourse_trials[tr] = tcourse[tr*t_len:(tr+1)*t_len]\n",
    "                tcourses.append(tcourse_trials)\n",
    "                freqs, psd = statesPSD(gamma, n_states, xe, fs=256/downsamp_rate)\n",
    "                psd = psd[np.newaxis,]\n",
    "                psds.append(psd)\n",
    "                IC_new_list.append(IC)\n",
    "                print(\"%s seconds\" % (tm.time() - start_time))\n",
    "                print(f\"subj{subj}, IC{IC}: OK\")\n",
    "            except:\n",
    "                print(f\"subj{subj}, IC{IC}: NOT POSSIBLE\")\n",
    "                    print(\"Saving the states timecourses and PSDs\")\n",
    "        print(f\"Saving the probability time course and the PSD of each states for subj{subj}\")\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"states_timecourse\": ((\"IC\", \"trials\",\"time\", \"states\"), np.concatenate((psds))),\n",
    "                \"states_psd\": ((\"IC\", \"states\", \"freq\"), np.concatenate((psds))),\n",
    "            },\n",
    "            {\n",
    "                \"IC\":IC_new_list,\n",
    "                \"time\":data[\"time_axis\"][::downsamp_rate],\n",
    "                \"states\":np.arange(1, n_states+1),\n",
    "                \"freq\": freqs,\n",
    "            }\n",
    "        )\n",
    "        frac_occ = 0 ######### FINIR\n",
    "        ds = ds.assign(frac_occ = (ds[\"states_timecourse\"].sum(\"trials\")/ds.sizes[\"trials\"]))\n",
    "        ds.to_netcdf(f\"tde-hmm2/test_files/su{subj}-{n_states}states_woPCA_preModel_data_Multi.nc\")\n",
    "\n",
    "\n",
    "sec_time = tm.time() - complete_time\n",
    "hr_time = int(sec_time/3600)\n",
    "sec_time = sec_time - (hr_time*3600)\n",
    "mn_time = int(sec_time/60)\n",
    "sec_time = sec_time - (mn_time*60)\n",
    "print(f\"{hr_time}h{mn_time}mn{sec_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
