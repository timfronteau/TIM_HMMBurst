{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from loader import load_oneIC\n",
    "import h5py\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from hmmlearn import hmm\n",
    "import scipy.signal as signal\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from wavelet_transform import wavelet_transform2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/INT/malfait.n/Documents/NIC_250819\"\n",
    "file = \"FCK_LOCKED_IC_JYOTIKA_250819.mat\"\n",
    "\n",
    "path = f\"{directory}/{file}\"\n",
    "\n",
    "mat_file = h5py.File(path, \"r\")\n",
    "cells_refs = mat_file['FCK_LOCKED_IC_JYOTIKA']\n",
    "\n",
    "n_IC = 4\n",
    "n_subj = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = \"tde-hmm2/Multivariate/figures/\"\n",
    "data_dir = \"tde-hmm2/Multivariate/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedx function copies the `x` array len(lags) times into `xe`\n",
    "# with lags (i.e. time delays) between lags[0] and lags[-1] (we implement the time-delay array for the HMM).\n",
    "\n",
    "def embedx(x, lags):\n",
    "    \n",
    "    Xe = np.zeros((x.shape[1], x.shape[0],  len(lags)))\n",
    "\n",
    "    for l in range(len(lags)):\n",
    "        Xe[:, :, l] = np.roll(x, lags[l], axis=0).swapaxes(0, 1)\n",
    "\n",
    "    # Remove edges\n",
    "    valid = np.ones((x.shape[0], 1), dtype=np.int8)\n",
    "    valid[:np.abs(np.min(lags)), :] = 0\n",
    "    valid[-np.abs(np.max(lags)):, :] = 0\n",
    "\n",
    "    Xe = Xe[:, valid[:, 0] == 1, :]\n",
    "\n",
    "    return Xe, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statesPSD(gamma, n_states, xe, fs=256/3):\n",
    "\n",
    "    psd_all = []\n",
    "    for i in range(n_states):\n",
    "\n",
    "        # Compute PSD separately for each lag\n",
    "        tot = []\n",
    "        for seg in xe[gamma[:, i]>(2/3), :].T:\n",
    "            freqs, psd = signal.welch(x=seg, fs=fs, nfft=1000)\n",
    "            tot.append(psd)\n",
    "        psd = np.mean(np.asarray(tot), 0)\n",
    "        psd_all.append(psd)\n",
    "    \n",
    "    psd_all = np.asarray(psd_all)\n",
    "    \n",
    "    return freqs, psd_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imput data parameters\n",
    "# subj_list = [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23] # All except 1, 9, 13, 15\n",
    "# subj_list = [2, 3, 4, 6, 7, 8, 10, 11, 14, 16, 18, 19, 22] # same && all IC exist\n",
    "subj_list = [2]\n",
    "IC_list = [1, 2, 3, 4]\n",
    "# IC_list = [1, 2]\n",
    "downsamp_rate = 3\n",
    "# downsamp_rate = 1\n",
    "lags = np.arange(-5, 5)\n",
    "# lags = np.arange(-29, 29)\n",
    "# lags = np.arange(-11, 12)\n",
    "n_lags = lags.shape[0]\n",
    "apply_PCA = False  # Do we apply a PCA before inferring the HMM?\n",
    "n_components = 0     # Number of principal components in case of PCA\n",
    "# n_components = 40\n",
    "\n",
    "### HMM parameters\n",
    "all_subj_first = False    # Do we compute the model on all subjects before refining it for each subject?\n",
    "model_type = 'GaussianHMM'\n",
    "covariance_type = 'full'\n",
    "# covariance_type = 'diag'  # ONLY IN CASE OF PCA\n",
    "n_iter = 100\n",
    "tol = 0.01\n",
    "\n",
    "### Output data parameters\n",
    "# n_states_list = [3, 4, 5, 6]    # Number of hidden Markov states. Must be a list.\n",
    "n_states_list = [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script\n",
    "\n",
    "The model on all subjects can only be computed on subjects that have the same number of Independent Components (here 4IC). But then, the refining using the parameters found can be done on all subjects, no matter the number of ICs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_subj_first:\n",
    "    print(\"Computing the imput matrix for the model\")\n",
    "    subj_lengths = []\n",
    "    tde_imput = []\n",
    "    for subj in subj_list:\n",
    "        # Loading all data for subject{subj}\n",
    "        xeall = []\n",
    "        if apply_PCA:\n",
    "            pcaall = []\n",
    "        for IC in IC_list:\n",
    "            data, n_trials = load_oneIC(mat_file, cells_refs, subj, IC, comp=False)\n",
    "            big_timecourse = np.concatenate([data[f'raw_timecourse_256Hz'][i][::downsamp_rate] for i in range(100)])\n",
    "                # Downsampled to 256/3 = 85,33333Hz\n",
    "            big_timecourse = scale(big_timecourse)\n",
    "            x = big_timecourse.reshape(-1, 1)\n",
    "            xe, valid = embedx(x, lags)\n",
    "            xeall.append(xe[0, :, :])\n",
    "            if apply_PCA:\n",
    "                pca = PCA(n_components=n_components)\n",
    "                pcaall.append(pca.fit_transform(xe[0, :, :]))\n",
    "            print(f\"IC{IC} loaded\")\n",
    "        if apply_PCA:\n",
    "            y = np.concatenate(pcaall, axis=1)\n",
    "        else:\n",
    "            y = np.concatenate(xeall, axis=1)\n",
    "        tde_imput.append(y)\n",
    "        subj_lengths.append(xe.shape[1])\n",
    "    tde_imput = np.concatenate(tde_imput)\n",
    "\n",
    "    for n_states in n_states_list:\n",
    "        start_time = tm.time()\n",
    "        print(f\"Computing and saving the general model for {n_states} states\")\n",
    "        model = hmm.GaussianHMM(n_components=n_states, n_iter=n_iter,\n",
    "                                covariance_type=covariance_type, tol=tol)\n",
    "        model.fit(tde_imput, subj_lengths)\n",
    "\n",
    "        with open(data_dir + f\"ALLSUBJECTS_st{n_states}_lg{n_lags}co{n_components}\"\n",
    "            + \"Multivariate\" + model_type + \".pkl\", \"wb\") as file: pickle.dump(model, file)\n",
    "        print(\"%s seconds\" % (tm.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the imput matrix for the model\n",
      "Loading the raw timecourse\n",
      "IC1 loaded\n",
      "Loading the raw timecourse\n",
      "IC2 loaded\n",
      "Computing and saving the model\n",
      "Computing the PSD of each state\n",
      "Saving the states timecourses and PSDs\n",
      "222.4885814189911 seconds\n",
      "su3, 3 states done\n"
     ]
    }
   ],
   "source": [
    "for n_states in n_states_list:\n",
    "    if all_subj_first:\n",
    "        file = open(data_dir + f\"ALLSUBJECTS_st{n_states}_lg{n_lags}co{n_components}\"\n",
    "                + \"Multivariate\" + model_type + \".pkl\", \"rb\")\n",
    "        model = pickle.load(file)\n",
    "        model.init_params = 'st'\n",
    "\n",
    "    for subj in subj_list:\n",
    "        start_time = tm.time()\n",
    "        # Loading all data for subject{subj}\n",
    "        print(\"Computing the imput matrix for the model\")\n",
    "        xeall = []\n",
    "        if apply_PCA:\n",
    "            pcaall = []\n",
    "        for IC in IC_list:\n",
    "            try:\n",
    "                data, n_trials = load_oneIC(mat_file, cells_refs, subj, IC, comp=False)\n",
    "                big_timecourse = np.concatenate([data[f'raw_timecourse_256Hz'][i][::downsamp_rate] \n",
    "                                                 for i in range(n_trials)])\n",
    "                    # Downsampled to 256/3 = 85,33333Hz\n",
    "                big_timecourse = scale(big_timecourse)\n",
    "                x = big_timecourse.reshape(-1, 1)\n",
    "                xe, valid = embedx(x, lags)\n",
    "                xeshape = xe[0].shape\n",
    "                xeall.append(xe[0, :, :])\n",
    "                if apply_PCA:\n",
    "                    pca = PCA(n_components=n_components)\n",
    "                    pcaall.append(pca.fit_transform(xe[0, :, :]))\n",
    "                print(f\"IC{IC} loaded\")\n",
    "            except:\n",
    "                xeall.append(np.zeros(1))\n",
    "                if apply_PCA:\n",
    "                    pcaall.append(np.zeros(1))\n",
    "        for i in range(len(IC_list)):\n",
    "            if xeall[i].shape[0]==1:\n",
    "                xeall[i] = np.zeros(xeshape)\n",
    "                if apply_PCA:\n",
    "                    pcaall[i] = np.zeros(xeshape)\n",
    "        if apply_PCA:\n",
    "            y = np.concatenate(pcaall, axis=1)\n",
    "        else:\n",
    "            y = np.concatenate(xeall, axis=1)\n",
    "        print(\"Computing and saving the model\")\n",
    "        if all_subj_first==False:\n",
    "            model = hmm.GaussianHMM(n_components=n_states, n_iter=n_iter,\n",
    "                                covariance_type=covariance_type, tol=tol)\n",
    "        model.fit(y)\n",
    "        gamma = model.predict_proba(y)\n",
    "        with open(data_dir + f\"su{subj}_st{n_states}_lg{n_lags}co{n_components}\"\n",
    "                    + \"Multivariate\" + model_type + \".pkl\", \"wb\") as file: pickle.dump(model, file)\n",
    "        print(\"Computing the PSD of each state\")\n",
    "        psds = []\n",
    "        for i in range(len(IC_list)):\n",
    "            freqs, psd = statesPSD(gamma, n_states, xeall[i])\n",
    "            psd = psd[np.newaxis,]\n",
    "            psds.append(psd)\n",
    "        # Save the states timecourses and PSDs thanks to xarray and netCDF\n",
    "        print(\"Saving the states timecourses and PSDs\")\n",
    "        tcourse = np.concatenate(\n",
    "            (np.zeros((abs(lags[0]),n_states)), gamma, np.zeros((lags[-1],n_states)))\n",
    "        )\n",
    "        time_axis = data[\"time_axis\"][::downsamp_rate]\n",
    "        t_len = time_axis.shape[0]\n",
    "        tcourse_trials = np.zeros((n_trials, t_len, n_states))\n",
    "        for tr in range(n_trials):\n",
    "            tcourse_trials[tr] = tcourse[tr*t_len:(tr+1)*t_len]\n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"states_timecourse\": ((\"trials\",\"time\", \"states\"), tcourse_trials),\n",
    "                \"states_psd\": ((\"IC\", \"states\", \"freq\"), np.concatenate((psds))),\n",
    "            },\n",
    "            {\n",
    "                \"IC\":IC_list,\n",
    "                \"time\":time_axis,\n",
    "                \"states\":np.arange(1, n_states+1),\n",
    "                \"freq\": freqs,\n",
    "            }\n",
    "        )\n",
    "        ds = ds.assign(frac_occ = (ds[\"states_timecourse\"].sum(\"trials\")/ds.sizes[\"trials\"]))\n",
    "        ds.to_netcdf(data_dir + f\"su{subj}_st{n_states}_lg{n_lags}co{n_components}_data.nc\", mode=\"w\")\n",
    "        print(\"%s seconds\" % (tm.time() - start_time))\n",
    "        print(f\"su{subj}, {n_states} states done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the raw timecourse\n",
      "Loading the raw timecourse\n"
     ]
    }
   ],
   "source": [
    "info = mne.create_info(ch_names=['signal'], sfreq=256, ch_types=['eeg'])\n",
    "\n",
    "for n_states in n_states_list:\n",
    "    widths = [14, 1, 5]\n",
    "    heights = [1 for i in range(n_states)] + [4,4,4,4]\n",
    "    gs_kw = dict(width_ratios=widths, height_ratios=heights, wspace=0.0, hspace=0.0)\n",
    "\n",
    "    for subj in subj_list:\n",
    "        fig, f_axes = plt.subplots(figsize=(sum(widths),sum(heights)), ncols=3, nrows=(n_states+4), constrained_layout=True,\n",
    "                                 gridspec_kw=gs_kw)\n",
    "        ds = xr.open_dataset(data_dir + f\"su{subj}_st{n_states}_lg{n_lags}co{n_components}_data.nc\")\n",
    "        for state in ds[\"states\"].values:_\n",
    "            ax = f_axes[state-1,0]\n",
    "            ax.plot(ds[\"time\"].values, ds[\"frac_occ\"].values[:, state-1], color=f\"C{state-1}\")\n",
    "            ax.set_xlim([-4, 3])\n",
    "            ax.set_ylabel(f\"state {state}\")\n",
    "        for IC in ds[\"IC\"].values:\n",
    "            try:\n",
    "                ax = f_axes[IC+n_states-1,0]\n",
    "                data, n_trials = load_oneIC(mat_file, cells_refs, subj, IC, comp=False)\n",
    "                tfr = wavelet_transform2(data, info, trial=np.arange(1,n_trials+1))\n",
    "                mappable = ax.imshow(tfr[0], aspect='auto', origin='lower', extent=[-4, 3, 2, 50], \n",
    "                                       norm=colors.PowerNorm(gamma=0.5), cmap='RdYlBu_r')\n",
    "                ax.set_ylabel(f'Frequencies IC{IC} (Hz)')\n",
    "                fig.colorbar(mappable, cax=f_axes[IC+n_states-1,1])\n",
    "            except:\n",
    "                pass\n",
    "        for i in range(len(ds[\"IC\"].values)):\n",
    "            IC = ds[\"IC\"].values[i]\n",
    "            ax = f_axes[IC+n_states-1,2]\n",
    "            ax.plot(ds[\"freq\"].values, ds[\"states_psd\"].values[i,].T)\n",
    "            ax.set_ylabel(f'PSD IC{IC}')\n",
    "        ax = f_axes[n_states,2]\n",
    "        lines = ax.get_lines()\n",
    "        labels = [f\"State {i}\" for i in range (1, n_states+1)]\n",
    "        ax = f_axes[0,2]\n",
    "        ax.legend(lines, labels, loc='upper left')\n",
    "        ax = f_axes[n_states+3,0]\n",
    "        ax.set_xlabel(f'Time (s)') \n",
    "        ax = f_axes[n_states+3,2]\n",
    "        ax.set_xlabel(f'Frequency (Hz)')   \n",
    "\n",
    "        fig.savefig(figures_dir + f'grid-{n_states}states-subj{subj}.png', dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_to_plot = 5\n",
    "\n",
    "for n_states in n_states_list:\n",
    "    for subj in subj_list:\n",
    "        fig, f_axes = plt.subplots(figsize=(20,n_states*n_trials_to_plot), ncols=1, nrows=(n_states*n_trials_to_plot), constrained_layout=True)\n",
    "        ds = xr.open_dataset(data_dir + f\"su{subj}_st{n_states}_lg{n_lags}co{n_components}_data.nc\")\n",
    "        for state in range(1, n_states+1):\n",
    "            color = f\"C{state-1}\"\n",
    "            for trial in range(1, n_trials_to_plot+1):\n",
    "                ax = f_axes[n_trials_to_plot*(state-1)+trial-1]\n",
    "                ax.fill_between(ds[\"time\"], ds[\"states_timecourse\"].values[trial, :, state-1], color=color)\n",
    "                ax.set_xlim([-4, 3])\n",
    "                ax.set_ylim([0, 1])\n",
    "                ax.set_ylabel(f\"Prob. st{state} tr{trial}\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        fig.savefig(figures_dir + f'tcourses-{n_states}states-subj{subj}.png', dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
